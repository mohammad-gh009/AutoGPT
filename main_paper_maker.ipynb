{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMeBeGII4296/r3zPQCIn67",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad-gh009/AutoGPT/blob/master/main_paper_maker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXUmmxbMKDkV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "chuhAz5Ch2Qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d448a1ba-8d39-4c63-87b2-e447d34ff38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.2\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.25.2)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.42.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "    load_in_bbit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "WxVDLQ1skKaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "TrQ3CexfkoiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"h2oai/h2ogpt-gm-7b-mistral-chat-sft-dpo-rag-v1\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"h2oai/h2ogpt-gm-7b-mistral-chat-sft-dpo-rag-v1\", device_map=\"auto\", load_in_4bit=True)"
      ],
      "metadata": {
        "id": "g6e5Vu2XPui6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525,
          "referenced_widgets": [
            "0bf1c00634e14d9cb26b448fd15a87a1",
            "d8c0e6433f094aef8f575c68fc9a4540",
            "6cf8b741117240c08b925b523aec75d5",
            "85781009ae6740c18c34b1c6e6c7bb36",
            "5ddde3f04be64b9587dd17d7789514d0",
            "b22c2e7598094fc7909b3a5033b492ed",
            "47f7618a70794d2cbc1402fe8b04576b",
            "5840dc1477b84c38b87d01d04390bc16",
            "7f4397739e924b7dbe44c9b94a95a49a",
            "f7c0ee9975434a27ada3e82f1a6ebfff",
            "fc42c4cf10704daf84934a252b5990ec",
            "9a0990de355346b5b1741565f6e6739d",
            "f3f7b96fabd9429a8433c2443f203807",
            "558d31fcaa324edda68838c6679bc36d",
            "1ac72b327399414eb76f7a1f6f789350",
            "16006b33697f40b5936fd3964c116a12",
            "638a9c68d0074f05966f5fd2d2f15de1",
            "656b1300627b40c6bcc59e48c6e722a5",
            "a3c055f3ad7a46c99a6ee4c00be0486f",
            "bf439820bdb74138823085342962ca2e",
            "6013416ee24d4bf691234f84da436f63",
            "6afbb556f70d4580a1d9c3008986dc4c",
            "47f3cf8c2d8a4fb281f22df92c433b91",
            "9716b0a7e0534f8787e34997d21d357d",
            "31546e9af598498d86f718dc7f51d25a",
            "d6a6940191124de8a72515dae1e8ed1a",
            "cdbac0a222b641a2a94e2b5a3e8db1a9",
            "2d1aa51c472441e5bd662800cdf7b61b",
            "cc9efe893a73440eb13adc7fdee35e5d",
            "8e1dcd9c44284ea8a36aecaf60012d02",
            "fbef5241432445818214433c8dd98ca1",
            "03d20c3308be4dadbf9eac89a8de25be",
            "9c687de0738b492d80c5260d0141f5e3",
            "dbda77a20fae4b24b3034f9204a215c2",
            "e5baa74397fd42958d2be10fe9901dd3",
            "5a3eb977bc304223bbfd64f159a31203",
            "8eb8d6f2456c498fac188b3cacabe706",
            "d8bb4db119e647b9b0d45b4c9c8e9ec2",
            "7bd8ed6e6560402b893cbd0b891e3f5d",
            "f1283cc0655f494fb3b64adb8929df0d",
            "56b6aa3ea62b49a1aca736f246c2be41",
            "cfcb0ffe3a914dfb9227219485b58edf",
            "46a9bfefd9fd4d09b3d48b83523c0459",
            "5d7e891329d54d01be23e6537efe1882",
            "a7e4074c31e5423a9c5db499e2f9a353",
            "8fec2a1ae2b64184acf3c886a8f37051",
            "87d3b944e0b04d4bab06f1c67eee6710",
            "c03be9014ba54623a1c5350aab5fe855",
            "aaf5ef61e8a64cc48cb00a9585a12487",
            "491f8b5bd164488884c56c4c1811ad0c",
            "83b8377dd3304c74a583a94ac39dd4b4",
            "cf10ff8f255e427fb66f57a1eecdf435",
            "5c9e57b757cd4316bed5573af497fa69",
            "fd4fd5209fdb447597c4c7ef6d7a9775",
            "295205b33f3e432f96a41a09d020e4e2",
            "d0c2ec945d3545619aa87ec1cb7f82c1",
            "6da6dd5541b54dbdab7996a41f439c19",
            "83d28e7c353f4e72acf7d697eb556607",
            "65f43e010f1a4d489b4161dab73d50d0",
            "2a6f6077ebd44d29b9f7aff2c8e74ea8",
            "734f925b47d54ac5955b6471adf61170",
            "1c2790bba5e84d9197932d1027a03c5f",
            "4007b44519244604ad5139674e19a5f7",
            "51f75471daee4d7984c3ab8995749462",
            "e15cdf2cdbe749b3930fe424f51a3c45",
            "c2782afcfcaf4ad694448eff4cd9ad53",
            "c9fa9f52151b4d7299f6ae8b053750a3",
            "9b637849de7e4ed89f0756fff5cc9e7d",
            "6d36a5b24c2243afb1470cf6e2c5fb9d",
            "bd60b7221b0e4a80ac9e2c1187b9fcb8",
            "bf802e90297f4ace9efdce3bddc2645c",
            "9428f25d89a346c5b65309f56c680fd2",
            "1b498cc15c8a49c9896700f5afb35428",
            "31305718b22b4aa6a04e7251f8746a15",
            "21d09e2ebaff4c3abaa16bb796804a9b",
            "ed5eff4e1026436aa69b2d0dd5a8238b",
            "2b827be28fc945c382f0a3ca945493ff",
            "35526a76587f405495cdba6518b049b9",
            "e3bd7e4e038e4121b9bcb875c10f5f58",
            "4a0634a7d57b4254ad40931267420542",
            "b64c75d141e643cca173679566ee4b00",
            "32494140f18848d1b832503dd764d1e2",
            "1d99e17ce260481da7aa6f5474ee381a",
            "3d732f42f4b047dd84dc3ab2413e1372",
            "716a2aa13b5e4e86a33b7e0c8b1e1f51",
            "2fd6325576c640ebb0d0232a5ad90f42",
            "7ba301eed4f24f588da929c947a45d4f",
            "52ffa0eaf3b144bb9db17a331eac47f7",
            "086d04a45eef4ab1963ed25b8a50761b",
            "8e9c6bc0f0d844dfbb07787a55677c54",
            "42bfe72b67894a34802b37514c37aeb7",
            "9ef65ae0121d48ca8060271744604026",
            "673df32535924df2bf9a0f4090fcad9d",
            "6145854262c14c6ca83ec9ed119c2590",
            "76b7bc44f8324a4f9687c06b91d67e13",
            "77d26d15106743f5af3d578244b71981",
            "f71375f29e34462fa0f4dbd8f0ce0728",
            "c184f530e43f4530bc14ff801207ed58",
            "b6fdc17d31de4b90bdfbaa1abb4947f3",
            "9395c83388da49db8231265937260b01",
            "c6fdd234fc8d4e06b3080271940c15e4",
            "cd43a6aabc4f4a2892742ade131bce53",
            "61c95dab877b447ca38da772df30ee93",
            "862b6f081a984c70bdd7d52f828ac851",
            "7efaaf75ee33454999cbf5b087050799",
            "db2863c584ee43138bd9ba92ef6430d9",
            "9209d1313c4843879edc2bf5e469606d",
            "55d6f8f46cf74b08a5991d7d4303a29b",
            "26e5b92140054303a04ccbd4b82bf12e",
            "c1092c5f7d904fd7b2dc0dbf6a3447f9",
            "6bec61efad1c4631920b86f3b74e9956",
            "e1f4fe35826c41e28c64bddce592476b",
            "534c14debfc14f6594eb51979e6eba04",
            "88110cbb1f584281acc760e1e067ebb5",
            "a4dac5bc988a474088a65526e757b1bc",
            "33c468f1aad74b5981a99bb8c8418d2c",
            "6485f3f0a27644d69c6a298e6757dbb2",
            "352ca5360d594724be3f86e72cf7059f",
            "554e9e6bb713497f99b037dcfe6cf248",
            "9eaa0a5369f545d9ab33b3ce4ca18784",
            "1fd24e2fb1cd408d916493fdf18ae58f",
            "4e3bbd02a0e041b9bec60c674323feec",
            "b1c6095553de48288aa43fd6008ca4e4",
            "70cf7e39bd0447a88b09aac0c7b81c1e",
            "8e71f00959d84b37ab6eba6e2300401b",
            "6a8fbb2068a14f2788840c642ef6926c",
            "f57bdcabed13411e9949e7a365cc8f21",
            "b1c9486220ec4b1895c5c3c9ebfa6ae8",
            "8fa08f25a8014f7fb05351cdb0401ddb",
            "ef5b736b575c450eb84957cf9ae2e9fc",
            "34682c5b574f4638b808fa99c7fda1e1",
            "c838532ee39f48908999aac3f0e296c5"
          ]
        },
        "outputId": "a12f511d-2265-4648-940d-e46880163d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bf1c00634e14d9cb26b448fd15a87a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a0990de355346b5b1741565f6e6739d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47f3cf8c2d8a4fb281f22df92c433b91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbda77a20fae4b24b3034f9204a215c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7e4074c31e5423a9c5db499e2f9a353"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c2ec945d3545619aa87ec1cb7f82c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9fa9f52151b4d7299f6ae8b053750a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35526a76587f405495cdba6518b049b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "086d04a45eef4ab1963ed25b8a50761b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9395c83388da49db8231265937260b01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bec61efad1c4631920b86f3b74e9956"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e3bbd02a0e041b9bec60c674323feec"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an expert in extracting numbers from a text.\",\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": \"\"\"JUST give me ONE python list of citation indexes in numbers WITHOUT any other words from the following text:4.2. Model Application\n",
        "Not all the models are appropriate for all problems. Selecting a model depends on fac-\n",
        "tors such as the problem’s nature, the data’s size and quality, interpretability requirements,\n",
        "computational resources, and so on. A problem might be of the classiﬁcation, regression, or\n",
        "clustering type. Moreover, in a different taxonomy, either of the following types of models\n",
        "might be appropriate for a problem:\n",
        "•\n",
        "Supervised models: the algorithms learn from labeled data, where the input data are\n",
        "paired with corresponding target or output values. The goal is to predict these target\n",
        "values for new, unseen data. A few examples of supervised models are linear [133]\n",
        "and logistic regressions [134], decision trees [129], random forests [135], support vector\n",
        "machines [136], Convolutional Neural Networks [137], and Recurrent Neural Net-\n",
        "works [138]. Some examples, such as linear regression, could be used for classiﬁcation\n",
        "(ﬁnding the category of the data) and regression (ﬁnding the numerical value of the\n",
        "data), and some are speciﬁc to classiﬁcation or regression.\n",
        "•\n",
        "Unsupervised models: the algorithms work with unlabeled data, seeking to discover\n",
        "patterns, structures, or relationships within the data without explicit guidance on\n",
        "what to look for. They are also known as clustering algorithms. A few examples of\n",
        "unsupervised models are K-Means [139], Hierarchical Clustering [140], and Generative\n",
        "Adversarial Networks [141].\n",
        "•\n",
        "Reinforcement learning: an agent learns to make decisions by interacting with an\n",
        "environment. It receives feedback in the form of rewards or penalties based on its\n",
        "actions to maximize cumulative rewards over time. The most well-known example\n",
        "of this category is Q-Learning [142], which is used in tasks such as tic-tac-toe game\n",
        "playing and simple robot control.\n",
        "Moreover, a speciﬁc model is not guaranteed to be better than others. Choosing a\n",
        "model depends on various parameters, as mentioned before. However, algorithm selection\n",
        "is often an iterative process that needs reﬁning as more insights from experiments and data\n",
        "analysis are obtained.\"\"\"},\n",
        " ]"
      ],
      "metadata": {
        "id": "kpMAX4lzPuhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(messages):\n",
        "  tokenized_chat = tokenizer.apply_chat_template(messages , tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
        "  outputs = model.generate(tokenized_chat, max_new_tokens= 500)\n",
        "  text = tokenizer.decode(outputs[0]).split(\"<|answer|>\")[1]\n",
        "  return text"
      ],
      "metadata": {
        "id": "qGZEPV8Wb9Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = generator(messages)\n",
        "x"
      ],
      "metadata": {
        "id": "kYdO21pKfpQr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6598d32a-784e-404a-d250-e31265d16645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Here is a Python list of citation indexes in numbers without any other words:\\n\\n[133, 134, 129, 135, 136, 137, 138, 139, 140, 141, 142]</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.tokenize(x))"
      ],
      "metadata": {
        "id": "fI_OGdwMlo1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator(messages)"
      ],
      "metadata": {
        "id": "o83n_UaBcZlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_chat = tokenizer.apply_chat_template(messages , tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
        "outputs = model.generate(tokenized_chat, max_new_tokens= 1500)\n",
        "text = tokenizer.decode(outputs[0]).split(\"<|answer|>\")[1]"
      ],
      "metadata": {
        "id": "Lribh539Puen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an expert medical journal editor.\",\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\":\"edit the following  paragraph :\"+text },\n",
        " ]"
      ],
      "metadata": {
        "id": "sH9WfYLvPuYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzbIygQuPuWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_chat = tokenizer.apply_chat_template(messages , tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "K__DG6SCXkeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(tokenized_chat, max_new_tokens= 1000)"
      ],
      "metadata": {
        "id": "I2dDj6dqXkeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(outputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5a399c-4ccf-4d43-e07f-d1ce45d86d8f",
        "id": "oJ2V0tJpXkeT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "608"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e231330-2354-426f-b3f0-8902708c44fd",
        "id": "LoZtkMB9XkeU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|system|>You are an expert medical journal editor.</s> <|prompt|>edit the following  paragraph : The differential diagnosis of diabetes insipidus involves recognizing the differences between central or nephrogenic diabetes insipidus and primary polydipsia. It's crucial to differentiate these conditions because the treatments for each one may differ significantly. Reliable differentiation can be challenging, particularly when dealing with patients with primary polydipsia or partial forms of diabetes insipidus.\n",
            "\n",
            "Recent diagnostic algorithms rely on measuring copeptin levels after osmotic stimulation by hypertonic saline infusion or after nonosmotic stimulation by arginine. These methods have a higher diagnostic accuracy compared to the water deprivation test. In cases of central diabetes insipidus, nephrogenic diabetes insipidus, or primary polydipsia, treatment typically involves correcting existing water deficits. However, the specific approach to treatment will depend on the underlying cause of the condition.\n",
            "\n",
            "Central diabetes insipidus is characterized by a decrease in antidiuretic hormone (ADH) secretion due to damage to the hypothalamus or pituitary gland. This condition often results from tumors, radiation therapy, or other factors that affect the hypothalamic-pituitary axis. Treatment typically involves administering ADH replacement therapy, which can help restore normal urine concentrating ability.\n",
            "\n",
            "Nephrogenic diabetes insipidus occurs when the kidneys fail to respond</s> <|answer|> to ADH secretion, leading to excessive thirst and fluid loss. This condition is usually caused by a disorder of the renal tubules or the collecting ducts. Treatment typically involves replacing the missing ADH, either through intranasal administration of synthetic ADH or by intravenous infusion of recombinant human ADH.\n",
            "\n",
            "Primary polydipsia is a rare condition characterized by excessive thirst without any identifiable cause. It can be caused by various factors, including genetic mutations, autoimmune diseases, or metabolic disorders. Treatment typically involves managing the patient's thirst and hydration needs, as well as monitoring their electrolyte balance and blood pressure.\n",
            "\n",
            "In summary, the differential diagnosis of diabetes insipidus involves recognizing the differences between central or nephrogenic diabetes insipidus and primary polydipsia. Treatment approaches for each condition will vary depending on the underlying cause, but both involve addressing the patient's thirst and hydration needs.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.decode(outputs[0]).split(\"<|answer|>\")[1]"
      ],
      "metadata": {
        "id": "NsD5N8ziPuT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "Xqyp9Q2BYN9Z",
        "outputId": "6eaaa586-0b8b-48db-feea-e688db417d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" to ADH secretion, leading to excessive thirst and fluid loss. This condition is usually caused by a disorder of the renal tubules or the collecting ducts. Treatment typically involves replacing the missing ADH, either through intranasal administration of synthetic ADH or by intravenous infusion of recombinant human ADH.\\n\\nPrimary polydipsia is a rare condition characterized by excessive thirst without any identifiable cause. It can be caused by various factors, including genetic mutations, autoimmune diseases, or metabolic disorders. Treatment typically involves managing the patient's thirst and hydration needs, as well as monitoring their electrolyte balance and blood pressure.\\n\\nIn summary, the differential diagnosis of diabetes insipidus involves recognizing the differences between central or nephrogenic diabetes insipidus and primary polydipsia. Treatment approaches for each condition will vary depending on the underlying cause, but both involve addressing the patient's thirst and hydration needs.</s>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}